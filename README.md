# üöÄ EKS Challenge - Infraestrutura AWS com Terraform

Este projeto implementa uma infraestrutura b√°sica na AWS utilizando Terraform, provisionando uma VPC customizada e um cluster Amazon EKS funcional.

## üìã Vis√£o Geral da Solu√ß√£o

A solu√ß√£o foi desenvolvida seguindo boas pr√°ticas de Infrastructure as Code (IaC), com c√≥digo modular, reutiliz√°vel e bem documentado. A arquitetura implementada inclui:

- **VPC customizada** com CIDR configur√°vel
- **Subnets p√∫blicas e privadas** distribu√≠das em m√∫ltiplas zonas de disponibilidade
- **NAT Gateways** para permitir acesso √† internet das subnets privadas
- **Cluster EKS** com configura√ß√£o b√°sica funcional
- **Node Group gerenciado** com auto-scaling configurado
- **Security Groups** adequados para comunica√ß√£o entre componentes
- **IAM Roles e Policies** seguindo o princ√≠pio de menor privil√©gio

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         AWS Region                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    VPC (10.0.0.0/16)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Public Subnet   ‚îÇ      ‚îÇ  Public Subnet   ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (AZ-1a)        ‚îÇ      ‚îÇ   (AZ-1b)        ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                  ‚îÇ      ‚îÇ                  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ NAT GW 1   ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ NAT GW 2   ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                          ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ Internet  ‚îÇ                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  Gateway  ‚îÇ                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Private Subnet   ‚îÇ      ‚îÇ Private Subnet   ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (AZ-1a)        ‚îÇ      ‚îÇ   (AZ-1b)        ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                  ‚îÇ      ‚îÇ                  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ EKS Nodes  ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ EKS Nodes  ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ (Node      ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ (Node      ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  Group)    ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ  Group)    ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  EKS Cluster    ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  Control Plane  ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principais

1. **VPC (Virtual Private Cloud)**
   - CIDR: 10.0.0.0/16 (configur√°vel)
   - DNS hostnames e DNS support habilitados

2. **Subnets**
   - **P√∫blicas**: Para recursos que precisam de acesso direto √† internet (NAT Gateways)
   - **Privadas**: Para recursos que n√£o precisam de acesso direto (EKS Nodes)
   - Distribu√≠das em m√∫ltiplas zonas de disponibilidade para alta disponibilidade

3. **Internet Gateway**
   - Permite comunica√ß√£o entre a VPC e a internet

4. **NAT Gateways**
   - Um por zona de disponibilidade
   - Permite que recursos em subnets privadas acessem a internet para downloads e updates

5. **EKS Cluster**
   - Control plane gerenciado pela AWS
   - Endpoints p√∫blicos e privados habilitados
   - Logs de cluster habilitados (API, Audit, Authenticator, Controller Manager, Scheduler)

6. **EKS Node Group**
   - Inst√¢ncias EC2 gerenciadas pela AWS
   - Auto-scaling configur√°vel (min, max, desired)
   - Localizado em subnets privadas

7. **Security Groups**
   - Cluster SG: Permite tr√°fego HTTPS (443) do VPC
   - Node Group SG: Permite comunica√ß√£o entre nodes e com o cluster

8. **IAM Roles**
   - Cluster Role: Permiss√µes para o control plane do EKS
   - Node Group Role: Permiss√µes para os nodes (Worker Node Policy, CNI Policy, ECR ReadOnly)

## üìÅ Estrutura do Projeto

```
terraform_test/
‚îú‚îÄ‚îÄ main.tf                 # Configura√ß√£o principal e chamadas dos m√≥dulos
‚îú‚îÄ‚îÄ variables.tf            # Vari√°veis do projeto
‚îú‚îÄ‚îÄ outputs.tf             # Outputs do projeto
‚îú‚îÄ‚îÄ versions.tf            # Vers√µes do Terraform e providers
‚îú‚îÄ‚îÄ .gitignore            # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ README.md             # Este arquivo
‚îî‚îÄ‚îÄ modules/
    ‚îú‚îÄ‚îÄ vpc/
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf        # Recursos da VPC
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf   # Vari√°veis do m√≥dulo VPC
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf     # Outputs do m√≥dulo VPC
    ‚îî‚îÄ‚îÄ eks/
        ‚îú‚îÄ‚îÄ main.tf        # Recursos do EKS
        ‚îú‚îÄ‚îÄ variables.tf   # Vari√°veis do m√≥dulo EKS
        ‚îî‚îÄ‚îÄ outputs.tf     # Outputs do m√≥dulo EKS
```

## üöÄ Como Executar

### Pr√©-requisitos

1. **AWS CLI** instalado e configurado
   ```bash
   aws --version
   aws configure
   ```

2. **Terraform** instalado (vers√£o >= 1.5.0)
   ```bash
   terraform version
   ```

3. **Credenciais AWS** configuradas com permiss√µes adequadas para criar:
   - VPC e recursos relacionados
   - EKS clusters e node groups
   - IAM roles e policies
   - Security groups
   - NAT Gateways e Elastic IPs

### Passos para Execu√ß√£o

1. **Clone o reposit√≥rio** (ou navegue at√© o diret√≥rio)
   ```bash
   cd terraform_test
   ```

2. **Inicialize o Terraform**
   ```bash
   terraform init
   ```
   Este comando baixar√° os providers necess√°rios e inicializar√° o backend.

3. **Revise o plano de execu√ß√£o**
   ```bash
   terraform plan
   ```
   Este comando mostrar√° todos os recursos que ser√£o criados, modificados ou destru√≠dos.

4. **Aplique a configura√ß√£o**
   ```bash
   terraform apply
   ```
   Digite `yes` quando solicitado para confirmar a cria√ß√£o dos recursos.

   ‚ö†Ô∏è **Aten√ß√£o**: A cria√ß√£o do cluster EKS pode levar de 10 a 20 minutos.

5. **Configure o kubectl** (ap√≥s o apply)
   ```bash
   aws eks update-kubeconfig --region us-east-1 --name eks-challenge-dev-cluster
   ```
   Ou use o output do Terraform:
   ```bash
   terraform output -raw configure_kubectl
   ```

6. **Verifique o cluster**
   ```bash
   kubectl get nodes
   kubectl get pods --all-namespaces
   ```

7. **Destrua os recursos** (quando terminar)
   ```bash
   terraform destroy
   ```
   ‚ö†Ô∏è **Importante**: Execute este comando para evitar custos desnecess√°rios na AWS.

## ‚öôÔ∏è Configura√ß√£o e Vari√°veis

### Vari√°veis Principais

As vari√°veis podem ser configuradas atrav√©s de:
- Arquivo `terraform.tfvars` (n√£o versionado)
- Vari√°veis de ambiente (`TF_VAR_*`)
- Valores padr√£o no arquivo `variables.tf`

Principais vari√°veis:

| Vari√°vel | Descri√ß√£o | Padr√£o |
|----------|-----------|--------|
| `aws_region` | Regi√£o AWS | `us-east-1` |
| `project_name` | Nome do projeto | `eks-challenge` |
| `environment` | Ambiente (dev/staging/prod) | `dev` |
| `vpc_cidr` | CIDR da VPC | `10.0.0.0/16` |
| `availability_zones` | Zonas de disponibilidade | `["us-east-1a", "us-east-1b"]` |
| `eks_cluster_version` | Vers√£o do Kubernetes | `1.28` |
| `eks_node_instance_types` | Tipos de inst√¢ncia dos nodes | `["t3.medium"]` |
| `eks_node_desired_size` | N√∫mero desejado de nodes | `2` |
| `eks_node_min_size` | N√∫mero m√≠nimo de nodes | `1` |
| `eks_node_max_size` | N√∫mero m√°ximo de nodes | `3` |

### Exemplo de terraform.tfvars

```hcl
aws_region            = "us-east-1"
project_name          = "my-eks-project"
environment           = "dev"
vpc_cidr              = "10.0.0.0/16"
availability_zones    = ["us-east-1a", "us-east-1b"]
eks_cluster_version   = "1.28"
eks_node_instance_types = ["t3.medium"]
eks_node_desired_size = 2
eks_node_min_size     = 1
eks_node_max_size     = 3
```

## üéØ Decis√µes T√©cnicas

### 1. Modulariza√ß√£o
- **Decis√£o**: Separar VPC e EKS em m√≥dulos distintos
- **Justificativa**: Facilita reutiliza√ß√£o, manuten√ß√£o e testes. Cada m√≥dulo tem responsabilidade √∫nica.

### 2. Subnets P√∫blicas e Privadas
- **Decis√£o**: Usar subnets privadas para EKS nodes e p√∫blicas para NAT Gateways
- **Justificativa**: Seguran√ßa - nodes n√£o expostos diretamente √† internet, mas com acesso outbound via NAT.

### 3. M√∫ltiplas Zonas de Disponibilidade
- **Decis√£o**: Distribuir recursos em pelo menos 2 AZs
- **Justificativa**: Alta disponibilidade e resili√™ncia a falhas.

### 4. NAT Gateway por AZ
- **Decis√£o**: Criar um NAT Gateway por zona de disponibilidade
- **Justificativa**: Alta disponibilidade e melhor performance. Em produ√ß√£o, considere custos vs. benef√≠cios.

### 5. EKS Node Group Gerenciado
- **Decis√£o**: Usar Managed Node Group ao inv√©s de Self-Managed
- **Justificativa**: Menos overhead operacional, patches autom√°ticos, melhor integra√ß√£o com AWS.

### 6. Security Groups Restritivos
- **Decis√£o**: Configurar security groups com regras m√≠nimas necess√°rias
- **Justificativa**: Seguran√ßa - princ√≠pio do menor privil√©gio.

### 7. Tags Consistentes
- **Decis√£o**: Aplicar tags em todos os recursos usando `default_tags` e tags expl√≠citas
- **Justificativa**: Facilita gest√£o de custos, compliance e organiza√ß√£o.

### 8. Logs do Cluster Habilitados
- **Decis√£o**: Habilitar logs do control plane do EKS
- **Justificativa**: Observabilidade e troubleshooting facilitados.

## üîí Backend do Terraform

### Estado Local (Atual)

O projeto est√° configurado para usar backend local (padr√£o do Terraform). O arquivo de estado (`terraform.tfstate`) √© armazenado localmente.

### Backend Remoto (Recomendado para Produ√ß√£o)

Em um ambiente real de produ√ß√£o, recomenda-se usar um backend remoto. Exemplo de configura√ß√£o:

```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket"
    key            = "eks-challenge/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

**Benef√≠cios do backend remoto:**
- Estado compartilhado entre membros da equipe
- Locking de estado (evita conflitos)
- Versionamento do estado
- Backup autom√°tico
- Integra√ß√£o com CI/CD

**Configura√ß√£o necess√°ria:**
1. Criar bucket S3 para armazenar o estado
2. Criar tabela DynamoDB para locking
3. Configurar pol√≠ticas IAM adequadas
4. Adicionar a configura√ß√£o acima no `versions.tf`

## üêõ Dificuldades Encontradas

1. **Configura√ß√£o de Security Groups**
   - **Desafio**: Garantir comunica√ß√£o adequada entre cluster e nodes
   - **Solu√ß√£o**: Criar security groups espec√≠ficos e configurar regras de ingress/egress apropriadas

2. **IAM Roles e Policies**
   - **Desafio**: Entender quais pol√≠ticas s√£o necess√°rias para EKS funcionar corretamente
   - **Solu√ß√£o**: Seguir documenta√ß√£o oficial da AWS e usar managed policies quando poss√≠vel

3. **Depend√™ncias entre Recursos**
   - **Desafio**: Garantir ordem correta de cria√ß√£o (VPC ‚Üí Subnets ‚Üí EKS)
   - **Solu√ß√£o**: Usar `depends_on` explicitamente e aproveitar depend√™ncias impl√≠citas do Terraform

4. **C√°lculo de CIDRs para Subnets**
   - **Desafio**: Calcular CIDRs corretamente para m√∫ltiplas subnets
   - **Solu√ß√£o**: Usar fun√ß√£o `cidrsubnet()` do Terraform para c√°lculo autom√°tico

## üìä Pontos de Melhoria

### Para Ambiente de Produ√ß√£o

1. **Seguran√ßa**
   - Implementar Network ACLs adicionais
   - Restringir endpoints p√∫blicos do EKS (usar apenas privado com VPN/Bastion)
   - Habilitar encryption at rest para EBS volumes dos nodes
   - Implementar AWS WAF e Shield para prote√ß√£o adicional
   - Usar AWS Secrets Manager para credenciais
   - Implementar Pod Security Policies/Standards

2. **Observabilidade**
   - Integrar CloudWatch Container Insights
   - Configurar Prometheus e Grafana
   - Implementar logging centralizado (ELK Stack ou CloudWatch Logs)
   - Configurar alertas e dashboards
   - Implementar distributed tracing

3. **Escalabilidade**
   - Implementar Cluster Autoscaler
   - Configurar Horizontal Pod Autoscaler (HPA)
   - Considerar Fargate para workloads serverless
   - Implementar m√∫ltiplos node groups com diferentes instance types
   - Configurar Spot Instances para workloads tolerantes a interrup√ß√µes

4. **CI/CD**
   - Integrar com GitHub Actions, GitLab CI ou Jenkins
   - Implementar GitOps com ArgoCD ou Flux
   - Automatizar testes de infraestrutura (Terratest)
   - Implementar policy-as-code (OPA, Checkov)

5. **Backup e Disaster Recovery**
   - Configurar backup de volumes EBS
   - Implementar estrat√©gia de backup do etcd
   - Documentar procedimentos de DR
   - Testar regularmente procedimentos de failover

6. **Custos**
   - Implementar Reserved Instances ou Savings Plans
   - Usar Spot Instances onde apropriado
   - Monitorar e otimizar custos com AWS Cost Explorer
   - Implementar tags de custo mais detalhadas
   - Considerar NAT Instance ao inv√©s de NAT Gateway para reduzir custos (trade-off com HA)

7. **Governan√ßa**
   - Implementar AWS Organizations e SCPs
   - Configurar AWS Config para compliance
   - Implementar AWS Control Tower
   - Estabelecer pol√≠ticas de tagging obrigat√≥rias

## üìö Refer√™ncias Utilizadas

- [Terraform AWS Provider Documentation](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [Amazon EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/)
- [AWS VPC Best Practices](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html)
- [Conventional Commits](https://www.conventionalcommits.org/)
- [Terraform Best Practices](https://www.terraform.io/docs/cloud/guides/recommended-practices/index.html)

---

**‚ö†Ô∏è Lembrete**: Sempre execute `terraform destroy` ap√≥s concluir os testes para evitar custos desnecess√°rios na AWS.

